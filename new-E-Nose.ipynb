{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f555843-fd27-4ba8-93fb-290abd725504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import pickle \n",
    "import seaborn as sns\n",
    "import json\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn import svm\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045a0ec5-362a-4acc-a4a6-3c3b02e1d78e",
   "metadata": {},
   "source": [
    "**BELOW 2 CELLS SHOULD STRICTLY BE RUN ONLY IF YOU HAVE COLLECTED NEW TRAIN DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31d7b8c-1a16-4746-9d2c-aa8cb2dacb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-formatting JSON data recieced from sensor\n",
    "def add_line_to_json_file(file_path):\n",
    "    # Read the original JSON content\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Add the new line at the beginning\n",
    "    new_content = '{\"dataBlock\": [\\n' + content\n",
    "    new_content=new_content[:-11]\n",
    "    new_content=new_content.replace('] }', '] },')\n",
    "    new_content=new_content+\"] } ]}\"\n",
    "\n",
    "    # Write the modified content back to the file\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(new_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8366ae-39e6-46dd-9f1c-a6afa6e62bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the details asked to reformat the json data to right format\n",
    "num=int(input(\"Please enter the number of items trained: \"))\n",
    "list = []\n",
    "for i in range(num):\n",
    "    item=input(\"Please enter the item you trained: \")\n",
    "    file_path = f'/eNose-main/scripts/{item}.json'\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: The file at {file_path} does not exist.\")\n",
    "    else:\n",
    "        add_line_to_json_file(file_path)\n",
    "        print(f\"Successfully modified file {item}.json\")\n",
    "        list.append(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e8967d-a149-4342-9aed-11cf43087bed",
   "metadata": {},
   "source": [
    "**IF ABOVE TWO CELLS ARE RUN THEN COMMENT THE LINE IN BELOW CELL- list=['air','sanitizer','isopropylAlcohol']**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48259a1-a78b-4603-90d7-a1c87852edd9",
   "metadata": {},
   "source": [
    "**IT IS PRESENT IN LINE 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fdd539-adb3-4521-8e65-9cc2617e6ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable intelliense\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "# get label for the data\n",
    "dir = '/eNose-main/scripts/'\n",
    "csvFilename = \"psec2-data.csv\"\n",
    "f = open(csvFilename, \"w\")\n",
    "\n",
    "# Comment the below line if above 2 cells is run\n",
    "list=['air','sanitizer','isopropylAlcohol']\n",
    "\n",
    "header = \"sensor_id,time,temperature,pressure,humidity,gas_resistance,smell\"\n",
    "\n",
    "f.write(header + '\\n')\n",
    "\n",
    "for item in range(len(list)):\n",
    "\n",
    "    # convert collected json data into a csv file\n",
    "    jsonFilename = dir + list[item] + '.json'\n",
    "\n",
    "    parsed_json = \"\"\n",
    "    with open(jsonFilename) as json_file:\n",
    "      parsed_json = json.load(json_file)\n",
    "\n",
    "    #print(parsed_json)\n",
    "    i = 0\n",
    "    for block in parsed_json['dataBlock']:\n",
    "        #print(block)\n",
    "        #break\n",
    "        for data in block['datapoints']:\n",
    "            #print(data)\n",
    "            result = ''\n",
    "            #print(range(len(data) - 1))\n",
    "            for x in data:\n",
    "                result += str(x) + ','\n",
    "        \n",
    "            result += list[item]\n",
    "            #print(result)\n",
    "            f.write(result + '\\n')\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2d0d03-d27a-4991-b582-9cbac7b0dfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file into dataFrame\n",
    "dataset = pd.read_csv(csvFilename)\n",
    "print(str(len(dataset)) + ' records')\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6211f2c-21d3-419a-82c1-f6071f8f5419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "# 'Temperature','Pressure','Relative Humidity','Resistance Gassensor','Label Tag'\n",
    "X = dataset.loc[:,['humidity', 'gas_resistance']]\n",
    "y = dataset.loc[:, ['smell']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=32767, test_size=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4ef87b-856c-4afd-85c3-597c6e20b696",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train))\n",
    "print('-'*30)\n",
    "print(X_train.head())\n",
    "print('-'*30)\n",
    "print(len(y_train))\n",
    "print('-'*30)\n",
    "print(y_train.head())\n",
    "print(len(X_test))\n",
    "print('-'*30)\n",
    "print(X_test.head())\n",
    "print(len(y_test))\n",
    "print('-'*30)\n",
    "print(y_test.head())\n",
    "\n",
    "print('-'*30)\n",
    "list = y_test['smell'].values.tolist()\n",
    "print('air     :' + str(list.count('air')))\n",
    "print('tea :' + str(list.count('tea')))\n",
    "print('clove :' + str(list.count('clove')))\n",
    "print('coffee  :' + str(list.count('coffee')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8ce593-fbd8-44c9-8e98-dfa228772005",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature scaling\n",
    "sc_X = MinMaxScaler()\n",
    "X_trainSc = sc_X.fit_transform(X_train)\n",
    "X_testSc = sc_X.transform(X_test)\n",
    "\n",
    "print(X_test)\n",
    "print(X_testSc)\n",
    "\n",
    "tmpdf = pd.DataFrame(X_trainSc)\n",
    "print('-'*30)\n",
    "print(tmpdf.describe())\n",
    "\n",
    "# show histograms of the features\n",
    "print('-'*30)\n",
    "tmpdf.hist()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d21afaa-499b-49fb-b8c2-4c9f70545ada",
   "metadata": {},
   "source": [
    "**MODEL TRAINING AND SAVING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d9611b-04b9-4ec9-ac6e-d4b7314c33fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nearest Neighbors classification decision boundaries\n",
    "N_NEIGHBORS = 10\n",
    "\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap([\"pink\", \"lightblue\", \"yellow\"])\n",
    "cmap_bold = [\"orange\", \"lightgreen\", \"red\"]\n",
    "\n",
    "# create K Neighbours Classifier and fit data.\n",
    "classifier = KNeighborsClassifier(n_neighbors=N_NEIGHBORS, p=2,metric='euclidean', weights='uniform')\n",
    "classifier.fit(X_trainSc, y_train['smell'].values.tolist())\n",
    "\n",
    "# plot boundaires\n",
    "_, ax = plt.subplots()\n",
    "DecisionBoundaryDisplay.from_estimator(\n",
    "    classifier,\n",
    "    X_trainSc,\n",
    "    cmap=cmap_light,\n",
    "    ax=ax,\n",
    "    response_method=\"predict\",\n",
    "    plot_method=\"pcolormesh\",\n",
    "    xlabel=X.columns[0],\n",
    "    ylabel=X.columns[1],\n",
    "    shading=\"auto\",\n",
    ")\n",
    "\n",
    "# Plot training points\n",
    "scatter = sns.scatterplot(\n",
    "    x=X_trainSc[:, 0],\n",
    "    y=X_trainSc[:, 1],\n",
    "    hue=y_train['smell'],\n",
    "    palette=cmap_bold,\n",
    "    alpha=1.0,\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "scatter.set_xlim(left=-0.1, right=1.1)\n",
    "scatter.set_ylim(bottom=-0.1, top=1.1);\n",
    "    \n",
    "plt.title(\n",
    "    \"Classification Boundary (k = %i, weights = '%s')\" % (N_NEIGHBORS, 'uniform')\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a2d58d-74e6-4f4f-b1b0-9b1901e4930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the test set results\n",
    "y_pred = classifier.predict(X_testSc)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391ae89e-5a4b-46b3-bb0a-b0cdbbd1f495",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('f1_score       : ' + str(f1_score(y_test, y_pred, average=None)))\n",
    "print('accuracy_score : ' + str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70663e8-8658-471a-b076-038615bec22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory where you want to save the model\n",
    "directory = '/eNose-main/enose-api/'\n",
    "\n",
    "# Make sure the directory exists, create it if it doesn't\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Specify the full path including the filename\n",
    "modelFilename = os.path.join(directory, 'enoseModel.pkl')\n",
    "scFilename = os.path.join(directory, 'enoseSc.pkl')\n",
    "\n",
    "# Save model in binary mode\n",
    "with open(modelFilename, 'wb') as enosePickle:\n",
    "    pickle.dump(classifier, enosePickle)\n",
    "\n",
    "# Save fitted standardscalar in biniary mode\n",
    "with open(scFilename, 'wb') as enosePickle:\n",
    "    pickle.dump(sc_X, enosePickle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefbca6b-b757-4a42-82d3-f1c2a9aba68d",
   "metadata": {},
   "source": [
    "**CHANGE labels IF NEW TRAINING ITEM IS ADDED IN BELOW CELL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17b450d-e818-47bb-9ff7-677ba3227ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the model and scaler. Use them to run the smell detection using the same test data\n",
    "# to see if we get the same results as before\n",
    "\n",
    "# load the StandardScaler from disk and transform X_test\n",
    "loaded_ss = pickle.load(open(scFilename, 'rb'))\n",
    "print(loaded_ss)\n",
    "X_testSs = loaded_ss.transform(X_test)\n",
    "#X_testSs = X_test\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(modelFilename, 'rb'))\n",
    "print(loaded_model)\n",
    "y_pred = loaded_model.predict(X_testSs)\n",
    "\n",
    "# the confusion matrix hould be exactly the same as the previous one\n",
    "labels = [\"air\",\"isopropylAlcohol\",\"sanitizer\"]\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot()\n",
    "print('f1_score      : ' + str(f1_score(y_test, y_pred, average=None)))\n",
    "print('accuracy_score: ' + str(accuracy_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472ea2d2-1fea-4060-b9c8-5ce2b120e4a9",
   "metadata": {},
   "source": [
    "**BELOW CELL SETS UP FLASK SERVER AND SHOWS LIVE PREDICTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53772022-2321-4cc9-9365-628702f199fa",
   "metadata": {},
   "source": [
    "**REPLACE THE MQTT SETTINGS WITH THE RIGHT ONE ACCORDING TO YOUR COMPUTER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7132d9b-3602-4098-9c54-432fed3a3829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template_string, jsonify\n",
    "import random\n",
    "from threading import Thread\n",
    "import time\n",
    "import paho.mqtt.client as mqtt\n",
    "import pandas as pd\n",
    "import json\n",
    "import joblib  # For loading the model and scaler\n",
    "\n",
    "# Define MQTT settings\n",
    "MQTT_BROKER = \"192.168.196.213\"\n",
    "MQTT_PORT = 1883\n",
    "MQTT_TOPIC = \"sensorData\"\n",
    "MQTT_USERNAME = \"admin\"\n",
    "MQTT_PASSWORD = \"admin\" \n",
    "\n",
    "# File paths\n",
    "MODEL_PATH = '/eNose-main/enose-api/enoseModel.pkl'  \n",
    "SCALER_PATH = '/eNose-main/enose-api/enoseSc.pkl'\n",
    "\n",
    "# Placeholder for incoming data\n",
    "data_list = []\n",
    "counter=[]\n",
    "\n",
    "# Load your pre-trained ML model and scaler\n",
    "model = joblib.load(MODEL_PATH)\n",
    "scaler = joblib.load(SCALER_PATH)\n",
    "\n",
    "# Flask app setup\n",
    "app = Flask(__name__)\n",
    "current_prediction = {'prediction': 'Unknown', 'image_path': '/static/images/unknown.jpg'}  # Default prediction\n",
    "\n",
    "# HTML template as a string\n",
    "html_template = '''\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>E-nose prediction</title>\n",
    "    <style>\n",
    "        #image {\n",
    "            max-width: 100%;\n",
    "            height: auto;\n",
    "        }\n",
    "    </style>\n",
    "    <script>\n",
    "        async function updatePrediction() {\n",
    "            const response = await fetch('/current-prediction');\n",
    "            const data = await response.json();\n",
    "            const prediction = data.prediction;\n",
    "            const imagePath = data.image_path;\n",
    "            document.getElementById('prediction').innerText = prediction;\n",
    "            document.getElementById('prediction-image').src = imagePath;\n",
    "        }\n",
    "\n",
    "        window.onload = function() {\n",
    "            updatePrediction();\n",
    "            setInterval(updatePrediction, 2000); // Update every 2 seconds\n",
    "        }\n",
    "    </script>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>E-nose sensor prediction</h1>\n",
    "    <p>Predicted: <span id=\"prediction\">Loading...</span></p>\n",
    "    <img id=\"prediction-image\" src=\"/static/images/unknown.jpg\" alt=\"Prediction Image\">\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template_string(html_template)\n",
    "\n",
    "@app.route('/current-prediction')\n",
    "def current_prediction_route():\n",
    "    global current_prediction\n",
    "    return jsonify(current_prediction)\n",
    "\n",
    "# MQTT message handler\n",
    "def on_message(client, userdata, msg):\n",
    "    global data_list\n",
    "    global current_prediction\n",
    "    try:\n",
    "        # Decode the incoming message\n",
    "        message = msg.payload.decode()\n",
    "        \n",
    "        # Convert JSON string to Python dictionary\n",
    "        data = json.loads(message)\n",
    "        \n",
    "        # Extract datapoints from the received data\n",
    "        datapoints = data.get(\"datapoints\", [])\n",
    "        \n",
    "        # Print the received datapoints (for debugging)\n",
    "        print(\"Received datapoints:\", datapoints)\n",
    "        \n",
    "        # Extend data_list with the received datapoints\n",
    "        data_list.extend(datapoints)\n",
    "        \n",
    "        # Convert list to DataFrame\n",
    "        df = pd.DataFrame(data_list, columns=['index', 'timestamp', 'temperature', 'pressure', 'humidity', 'gas_resistance'])\n",
    "        \n",
    "        # Predict using the latest data point\n",
    "        latest_data = df.iloc[[-1]]  # Use the latest row for prediction\n",
    "        \n",
    "        # Apply the scaler to the latest data point\n",
    "        scaled_data = scaler.transform(latest_data.drop(['index', 'timestamp', 'temperature', 'pressure'], axis=1))  # Remove non-numeric columns\n",
    "        \n",
    "        # Make predictions using the model\n",
    "        prediction = model.predict(scaled_data)\n",
    "        \n",
    "        # Print the prediction (or handle it as needed)\n",
    "        print(f\"Prediction: {prediction}\")\n",
    "\n",
    "        counter.append(prediction[0])\n",
    "        \n",
    "        # Update the current_prediction based on the prediction\n",
    "        if len(counter) > 3:\n",
    "            if counter[-1] == counter[-2] == counter[-3]:\n",
    "                if counter[-1] == 'coffee':\n",
    "                    current_prediction['prediction'] = 'coffee'\n",
    "                    current_prediction['image_path'] = '/static/images/coffee.jpg'\n",
    "                elif counter[-1] == \"air\":\n",
    "                    current_prediction['prediction'] = 'air'\n",
    "                    current_prediction['image_path'] = '/static/images/air.jpg'\n",
    "                elif counter[-1] == \"sanitizer\":\n",
    "                    current_prediction['prediction'] = 'sanitizer'\n",
    "                    current_prediction['image_path'] = '/static/images/sanitizer.jpg'\n",
    "                elif counter[-1] == \"isopropylAlcohol\":\n",
    "                    current_prediction['prediction'] = 'isopropylAlcohol'\n",
    "                    current_prediction['image_path'] = '/static/images/isopropylAlcohol.jpg'\n",
    "            else:\n",
    "                current_prediction['prediction'] = 'Unknown'\n",
    "                current_prediction['image_path'] = '/static/images/unknown.jpg'\n",
    "        else:\n",
    "            current_prediction['prediction'] = 'Unknown'\n",
    "            current_prediction['image_path'] = '/static/images/unknown.jpg'\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing message: {e}\")\n",
    "\n",
    "# Set up MQTT client with authentication\n",
    "client = mqtt.Client()\n",
    "client.username_pw_set(MQTT_USERNAME, MQTT_PASSWORD)  # Set username and password\n",
    "client.on_message = on_message\n",
    "\n",
    "# Connect to the MQTT broker\n",
    "client.connect(MQTT_BROKER, MQTT_PORT, 60)\n",
    "\n",
    "# Subscribe to the MQTT topic\n",
    "client.subscribe(MQTT_TOPIC)\n",
    "\n",
    "# Start the MQTT client loop to begin listening for messages\n",
    "def start_mqtt_client():\n",
    "    client.loop_forever()\n",
    "\n",
    "# Start the Flask server in another background thread\n",
    "def run_app():\n",
    "    app.run(debug=True, use_reloader=False, port=5001)\n",
    "\n",
    "# Start the MQTT client loop in another background thread\n",
    "mqtt_thread = Thread(target=start_mqtt_client)\n",
    "mqtt_thread.start()\n",
    "\n",
    "# Start the Flask server in another background thread\n",
    "flask_thread = Thread(target=run_app)\n",
    "flask_thread.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e63d553-99be-46ee-ba1a-16b19d8ffdac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
